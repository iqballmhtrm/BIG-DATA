{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96b89db-690e-466e-886b-e2030481ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------+--------------------+-------------------+\n",
      "|transaction_id|user_id|  amount|               email|   transaction_time|\n",
      "+--------------+-------+--------+--------------------+-------------------+\n",
      "|         T0001|   U069|    NULL|jeffreyfisher@gma...|2025-04-20 08:00:02|\n",
      "|         T0002|   U253|70921.08| porteramy@yahoo.com|2025-03-30 21:07:41|\n",
      "|         T0003|   U222|42313.74|  jerome93@yahoo.com|2025-04-20 10:50:30|\n",
      "|         T0004|   U187|    NULL|jimeneztamara@sny...|2025-04-05 11:48:29|\n",
      "|         T0005|   U064|81176.73|   louis64@gmail.com|2025-04-14 08:50:35|\n",
      "+--------------+-------+--------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "jumlah baris: 1000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataCleaning\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"work/ecommerce_transactions_1000.csv\", header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "print(\"jumlah baris:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da832ba-e1e6-4489-b618-f1330f6ea244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+-----+----------------+\n",
      "|transaction_id|user_id|amount|email|transaction_time|\n",
      "+--------------+-------+------+-----+----------------+\n",
      "|             0|      0|   316|    0|              50|\n",
      "+--------------+-------+------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799a4519-8edf-4c43-8986-4f0063889d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah baris: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"jumlah baris:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d8de82-1024-4977-8aff-fdbe2eb11441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"transaction_time\"])\n",
    "df = df.fillna({\"amount\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "480b80dd-bce5-4d08-a592-75f8cdcd8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr, substring_index, col\n",
    "\n",
    "# Tambah kolom email_domain\n",
    "df = df.withColumn(\"email_domain\", substring_index(\"email\", \"@\", -1))\n",
    "\n",
    "# Filter hanya email yang mengandung '@'\n",
    "df = df.filter(instr(col(\"email\"), \"@\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3a388a-56aa-4f0e-bf4b-37087896f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Konversi kolom 'amount' ke DoubleType\n",
    "df = df.withColumn(\"amount\", col(\"amount\").cast(DoubleType()))\n",
    "\n",
    "# Konversi 'transaction_time' ke tanggal, dengan format eksplisit jika diperlukan\n",
    "df = df.withColumn(\"transaction_date\", to_date(col(\"transaction_time\"), \"yyyy-MM-dd\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4680030c-7d52-40dd-be4a-990a2502c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"cleaned_transactions_1000.csv\", header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e1bab3-23f8-4845-94ff-d65f2a0b50d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"transaction_time\").isNull()).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ecea1-47aa-44e4-a077-ca424e58e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    " Checklist Praktikum \n",
    "●\tDataset berhasil dibaca \n",
    "●\tStruktur schema dipahami \n",
    "●\tMissing value berhasil dihandle \n",
    "●\tEmail valid berhasil diproses \n",
    "●\tKolom baru  email_domain  dan  transaction_date  berhasil  dibuat \n",
    "●\tData bersih disimpan ulang \n",
    " Pertanyaan \n",
    "1.\tBerapa banyak data yang dibuang karena  transaction_time  kosong?\n",
    "jawab:\n",
    "    jumlah di hitung menggunakan \n",
    "    df.filter(col(\"transaction_time\").isNull()).count()\n",
    "\n",
    "2.\tApakah semua data  amount  sudah bertipe numerik setelah cleaning? \n",
    "jawab:\n",
    "    Ya, jika sudah di-cast ke DoubleType dan tidak ada null.\n",
    "\n",
    "3.\tKenapa lebih baik memperbaiki email invalid sebelum menganalisis data  transaksi?\n",
    "jawab:\n",
    "    Karena email invalid bisa membuat analisis salah dan tidak bisa digunakan\n",
    "    untuk identifikasi atau pengelompokan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c477db2-012f-4f6d-b76d-a5e961e199f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " Praktikum 2: Deteksi Outlier Sederhana di Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097281eb-d02e-4b6a-99c8-efff09ed5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "# Inisialisasi SparkSession\n",
    "spark = SparkSession.builder.appName(\"OutlierDetection\").getOrCreate()\n",
    "\n",
    "# Baca file CSV\n",
    "df = spark.read.csv(\"work/ecommerce_transactions_1000.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Ubah kolom amount jadi tipe double\n",
    "df = df.withColumn(\"amount\", col(\"amount\").cast(\"double\"))\n",
    "\n",
    "# Tambahkan kolom transaction_date dari transaction_time\n",
    "df = df.withColumn(\"transaction_date\", to_date(\"transaction_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0b310dd-dbfc-4250-a17c-70548cc1c8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Outliers: 331\n"
     ]
    }
   ],
   "source": [
    "# Hitung Q1 (25%) dan Q3 (75%)\n",
    "quantiles = df.approxQuantile(\"amount\", [0.25, 0.75], 0.01)\n",
    "Q1 = quantiles[0]\n",
    "Q3 = quantiles[1]\n",
    "\n",
    "# Hitung IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Tentukan batas bawah dan atas untuk outlier\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter outlier\n",
    "outliers = df.filter((df[\"amount\"] < lower_bound) | (df[\"amount\"] > upper_bound))\n",
    "\n",
    "# Cetak jumlah outlier\n",
    "print(\"Jumlah Outliers:\", outliers.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "629990a3-d754-4b73-83c9-32f8b5458f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Outliers: 331\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "|transaction_id|user_id|amount|               email|   transaction_time|transaction_date|\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "|         T0008|   U212|   NaN|  dgreen@hotmail.com|2025-04-23 07:19:12|      2025-04-23|\n",
      "|         T0010|   U033|   NaN|rebecca69@hotmail...|2025-04-15 04:04:31|      2025-04-15|\n",
      "|         T0013|   U184|   NaN|jackielewis@yahoo...|2025-03-29 21:00:47|      2025-03-29|\n",
      "|         T0014|   U130|   NaN|    dawn56@roman.net|2025-04-15 19:21:50|      2025-04-15|\n",
      "|         T0019|   U280|   NaN|   hgarcia@yahoo.com|2025-04-12 00:43:15|      2025-04-12|\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter baris yang merupakan outlier\n",
    "outliers = df.filter((df[\"amount\"] < lower_bound) | (df[\"amount\"] > upper_bound))\n",
    "\n",
    "# Menampilkan jumlah outliers\n",
    "print(\"Jumlah Outliers:\", outliers.count())\n",
    "\n",
    "# (Opsional) Menampilkan beberapa data outliers\n",
    "outliers.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e705fc1f-b1d3-4187-9d12-9af118833fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 = 34005.04, Q3 = 74468.55, IQR = 40463.51\n",
      "Lower Bound = -26690.225, Upper Bound = 135163.815\n",
      "Jumlah Outliers: 331\n"
     ]
    }
   ],
   "source": [
    "quantiles = df.approxQuantile(\"amount\", [0.25, 0.75], 0.05)\n",
    "Q1, Q3 = quantiles\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Q1 = {Q1}, Q3 = {Q3}, IQR = {IQR}\")\n",
    "print(f\"Lower Bound = {lower_bound}, Upper Bound = {upper_bound}\")\n",
    "\n",
    "outliers = df.filter((df[\"amount\"] < lower_bound) | (df[\"amount\"] > upper_bound))\n",
    "print(\"Jumlah Outliers:\", outliers.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e213688-f45f-41b9-ba34-b2009f38fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "|transaction_id|user_id|amount|               email|   transaction_time|transaction_date|\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "|         T0008|   U212|   NaN|  dgreen@hotmail.com|2025-04-23 07:19:12|      2025-04-23|\n",
      "|         T0010|   U033|   NaN|rebecca69@hotmail...|2025-04-15 04:04:31|      2025-04-15|\n",
      "|         T0013|   U184|   NaN|jackielewis@yahoo...|2025-03-29 21:00:47|      2025-03-29|\n",
      "|         T0014|   U130|   NaN|    dawn56@roman.net|2025-04-15 19:21:50|      2025-04-15|\n",
      "|         T0019|   U280|   NaN|   hgarcia@yahoo.com|2025-04-12 00:43:15|      2025-04-12|\n",
      "|         T0020|   U057|   NaN|    paul68@yahoo.com|2025-04-15 11:48:24|      2025-04-15|\n",
      "|         T0022|   U157|   NaN|    ysilva@gmail.com|2025-04-05 14:14:18|      2025-04-05|\n",
      "|         T0023|   U085|   NaN|   shawn41@yahoo.com|2025-04-26 23:15:02|      2025-04-26|\n",
      "|         T0025|   U126|   NaN|        davidsalinas|2025-04-09 15:47:48|      2025-04-09|\n",
      "|         T0028|   U110|   NaN|elizabethmclean@p...|2025-04-26 14:43:19|      2025-04-26|\n",
      "|         T0032|   U113|   NaN|taylorjoseph@hotm...|2025-04-16 07:45:18|      2025-04-16|\n",
      "|         T0033|   U060|   NaN|   debra62@gmail.com|2025-04-20 04:48:33|      2025-04-20|\n",
      "|         T0039|   U124|   NaN|bowmanryan@gmail.com|2025-04-23 11:25:05|      2025-04-23|\n",
      "|         T0040|   U200|   NaN|smithdanny@yahoo.com|2025-04-13 12:13:00|      2025-04-13|\n",
      "|         T0045|   U245|   NaN|garciajenny@crosb...|2025-04-20 00:46:25|      2025-04-20|\n",
      "|         T0046|   U123|   NaN|michaelaramos@yah...|2025-04-13 12:13:05|      2025-04-13|\n",
      "|         T0047|   U051|   NaN|    ubrown@reyes.com|2025-04-03 16:07:33|      2025-04-03|\n",
      "|         T0055|   U181|   NaN|michellehale@yaho...|2025-04-22 08:05:29|      2025-04-22|\n",
      "|         T0062|   U132|   NaN|michael35@hotmail...|2025-04-17 21:55:07|      2025-04-17|\n",
      "|         T0064|   U295|   NaN|andrea13@gallegos...|2025-04-20 11:05:49|      2025-04-20|\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = df.filter((df.amount < lower_bound) | (df.amount > upper_bound))\n",
    "outliers.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea5c218-1f02-42dc-95fb-06b9c0a4bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "|transaction_id|user_id|amount|               email|   transaction_time|transaction_date|\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "|         T0019|   U280|   NaN|   hgarcia@yahoo.com|2025-04-12 00:43:15|      2025-04-12|\n",
      "|         T0028|   U110|   NaN|elizabethmclean@p...|2025-04-26 14:43:19|      2025-04-26|\n",
      "|         T0020|   U057|   NaN|    paul68@yahoo.com|2025-04-15 11:48:24|      2025-04-15|\n",
      "|         T0014|   U130|   NaN|    dawn56@roman.net|2025-04-15 19:21:50|      2025-04-15|\n",
      "|         T0022|   U157|   NaN|    ysilva@gmail.com|2025-04-05 14:14:18|      2025-04-05|\n",
      "+--------------+-------+------+--------------------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.amount.desc()).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438c1ce-3109-4658-9f82-f3baae7cec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Penjelasan:\n",
    "Perintah ini mengurutkan data berdasarkan kolom amount secara menurun (desc()), lalu menampilkan 5 baris teratas. Ini berguna untuk mengetahui transaksi dengan nilai paling besar dalam dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad96ef3f-58b8-460b-8068-c10d4b5b7299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah total transaksi: 1000\n"
     ]
    }
   ],
   "source": [
    "total_transaksi = df.count()\n",
    "print(\"Jumlah total transaksi:\", total_transaksi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a51bd4-5bf5-4aa6-a629-92b5714c6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "Penjelasan:\n",
    "Fungsi count() menghitung jumlah baris dalam DataFrame, yang mewakili jumlah total transaksi. Ini membantu kita mengetahui skala data yang sedang dianalisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fedd2b36-db85-4e09-b8d2-757c4ed7430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah outlier: 331\n"
     ]
    }
   ],
   "source": [
    "jumlah_outlier = outliers.count()\n",
    "print(\"Jumlah outlier:\", jumlah_outlier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d09104e-3bc8-4950-99fb-993d73c5ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persentase outlier: 33.10%\n"
     ]
    }
   ],
   "source": [
    "persentase_outlier = (jumlah_outlier / total_transaksi) * 100\n",
    "print(f\"Persentase outlier: {persentase_outlier:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb034c-f867-4a3b-b228-126476b6ce05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
